<!DOCTYPE html>
<!-- custom.css -->
<link rel="stylesheet", href="/css/custom.css">

<!-- mathjax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      equationNumbers: {
        autoNumber: "AMS"
      }
    },
    tex2jax: {
      inlineMath: [ ['$','$'] ],
      displayMath: [ ['$$','$$'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
  });
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<!-- mermaid -->
<script src="/js/mermaid.min.js"></script>
<script>mermaid.initialize({startOnLoad:true});</script>

<!-- body -->
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Learning Theory | Everitt’s blog</title>
<meta name="generator" content="Jekyll v3.8.2" />
<meta property="og:title" content="Learning Theory" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Generalization error Questions that we might want to ask: Most learning algorithms fit their models to the training set, why should doing well on the training set tell us anything about generalization error? Can we relate error on the training set to generalization error? Are there conditions under which we can actually prove that learning algorithms will work well?" />
<meta property="og:description" content="Generalization error Questions that we might want to ask: Most learning algorithms fit their models to the training set, why should doing well on the training set tell us anything about generalization error? Can we relate error on the training set to generalization error? Are there conditions under which we can actually prove that learning algorithms will work well?" />
<link rel="canonical" href="http://localhost:8080/2017/08/02/learning_theory.html" />
<meta property="og:url" content="http://localhost:8080/2017/08/02/learning_theory.html" />
<meta property="og:site_name" content="Everitt’s blog" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2017-08-02T00:00:00+09:00" />
<script type="application/ld+json">
{"description":"Generalization error Questions that we might want to ask: Most learning algorithms fit their models to the training set, why should doing well on the training set tell us anything about generalization error? Can we relate error on the training set to generalization error? Are there conditions under which we can actually prove that learning algorithms will work well?","@type":"BlogPosting","url":"http://localhost:8080/2017/08/02/learning_theory.html","headline":"Learning Theory","dateModified":"2017-08-02T00:00:00+09:00","datePublished":"2017-08-02T00:00:00+09:00","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:8080/2017/08/02/learning_theory.html"},"@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="http://localhost:8080/feed.xml" title="Everitt's blog" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Everitt&#39;s blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a><a class="page-link" href="/category/blog.html">Blog</a><a class="page-link" href="/category/work.html">Work</a><a class="page-link" href="/tags.html">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Learning Theory</h1>
    <p class="post-meta">
      <time class="dt-published" datetime="2017-08-02T00:00:00+09:00" itemprop="datePublished">Aug 2, 2017
      </time></p>
  </header>

  <!-- Tags -->
  <ul class="tags">
    
  </ul>

  <!-- Body -->
  <div class="post-content e-content" itemprop="articleBody">
    <h3 id="generalization-error">Generalization error</h3>
<p><strong>Questions</strong> that we might want to ask:</p>
<ul>
  <li>Most learning algorithms fit their models to the training set, why should doing well on the training set tell us anything about generalization error?</li>
  <li>Can we relate error on the training set to generalization error?</li>
  <li>Are there conditions under which we can actually prove that learning algorithms will work well?</li>
</ul>

<p>$\newcommand{\E}{\operatorname{\mathbb{E}}}$
$\newcommand{\P}{\operatorname{\mathbb{P}}}$
$\newcommand{\R}{\operatorname{\mathbb{R}}}$</p>

<p><strong>Hoeffding inequality</strong> (Perhaps the most important inequality in learning theory)
<script type="math/tex">\P(\frac{1}{n}\sum_{i=1}^{n}(Z_i-\E(Z_i)) \geq t) \leq exp(-\frac{2nt^2}{(b-a)^2})</script></p>

<ol>
  <li>Markov’s inequality:
<script type="math/tex">\operatorname{\mathbb{P}}(Z\geq t) \leq \frac{\operatorname{\mathbb{E}}[Z]}{t}</script>
    <ul>
      <li>Let Z be an non-negative r.v and t &gt; 0</li>
      <li>Link to the <a href="http://cs229.stanford.edu/extra-notes/hoeffding.pdf">proof</a>.</li>
    </ul>
  </li>
  <li>Chebyshev’s inequality: A consequence of Markov’s inequality
<script type="math/tex">% <![CDATA[
\begin{split}
\operatorname{\mathbb{P}}(Z \geq \operatorname{\mathbb{E}}+t\; or \;Z \leq \operatorname{\mathbb{E}(Z)}-t) &= \operatorname{\mathbb{P}}((Z - \operatorname{\mathbb{E}(Z)})^2 \geq t^2) \\
& \leq \frac{\operatorname{\mathbb{E}}[(Z-\operatorname{\mathbb{E}}(Z))^2]}{t^2} = \frac{Var(Z)}{t^2}
\end{split} %]]></script>
    <ul>
      <li>What this means is that average of random variables with finite variance converges to their mean. Given enough samples.</li>
    </ul>
  </li>
  <li>Chernoff bounds
    <ul>
      <li>Essentially it’s saying, for any $\lambda$, we have $Z \geq \operatorname{\mathbb{E}}[Z] + t$ if and only if $e^{\lambda Z} \geq e^{\lambda \operatorname{\mathbb{E}}[Z] + \lambda t}$ or $e^{\lambda (Z-\operatorname{\mathbb{E}}[Z]) \geq e^{\lambda t}}$</li>
      <li>Chernoff bounds use moment generating functions in a way to give exponential deviation bounds.</li>
      <li>The Chernoff bounds proof is done based on the combination of the moment function of random variable and the markov inequality.</li>
      <li>It also works well with r.v that is the sum of i.i.d random variables. For example it gives bounds in exponential form for r.v that is the sum of i.i.d random variables.</li>
    </ul>
  </li>
  <li>Jensen’s inequality
    <ul>
      <li>The jensen’s inequality applies to convex functions. In our case, the most common ones are $f(x) = x^2$, $f(x) = e^x$ and $f(x) = e^{-x}$
<script type="math/tex">f(\E(x)) \leq \E (f(x))</script>
in terms of probability.
<script type="math/tex">f(tx_1 + (1-t)x_2) \leq tf(x_1) + (1-t)f(x_2)</script>
also in terms of convex function, for $t \in [0,1]$.</li>
      <li>Again, Jensen’s inequality for probability is just the infinite sums of integral of normal Jensen’s inequality.</li>
    </ul>
  </li>
  <li>Symmetrization
    <ul>
      <li>A technique in probability. This along with Jensen’s inequality is used to prove the Hoeffding’s lemma.</li>
    </ul>
  </li>
  <li>Hoeffding’s lemma
<script type="math/tex">\E[exp(\lambda(Z-\E[Z]))] \leq exp(\frac{\lambda^2(b-a)}{8})</script>
    <ul>
      <li>Let $Z$ be a bounded random variable with $Z \in [a,b]$, then the above holds for all $\lambda \in \R$</li>
    </ul>
  </li>
  <li>Hoeffding’s inequality conclusions:
    <ul>
      <li>Point 2 is proven via point 1.</li>
      <li>Point 3 is proven via point 1 in the exponential case. And its generalization applies well to sums of r.vs.</li>
      <li>Point 6 is proven via point 4 and point 5. It serves as intermediate part for proving the Hoeffding’s inequality.</li>
      <li>To prove Hoeffding’s inequality, we mainly use <strong>Hoeffding’s lemma</strong> and <strong>Chernoff bounds</strong> to do so. Namely we use point 3 and 6 to do so.</li>
      <li>Essentially one can interpret Hoeffding’s inequality like this:
        <ul>
          <li>The probability of of our estimate for the mean far from the the true mean is small as long as the sample size is large enough. Given each sample is i.i.d.</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<p><strong>Empirical risk/error</strong></p>

<p>For a binary classification problem, define empirical risk as:
<script type="math/tex">\hat{\xi}(h) = \frac{1}{m}\sum_{i=1}^{m}1\{h(x^{(i)}) \neq y^{(i)}\}</script></p>

<p><strong>Generalization error</strong></p>

<ul>
  <li>Define generalization error under the <strong>PAC</strong> assumptions.
    <ul>
      <li>traning and testing on the same distribution $D$</li>
      <li>independently drawn training examples</li>
    </ul>
  </li>
  <li>Define generalization error to be the probability that our model $h$ will misclassify our traning sample $(x,y)$</li>
</ul>

<script type="math/tex; mode=display">\xi(h) = P_{(x,y)\sim D}(h(x) \neq y)</script>

<ul>
  <li>
    <p>Note the difference between $\xi(h)$ and $\hat{\xi}(h)$</p>
  </li>
  <li>
    <p>Empirical risk minimization(ERM)
<script type="math/tex">\hat{\theta} = arg\; \min_{\theta}\hat{\xi}(h_{\theta})</script></p>
    <ul>
      <li>The most “basic” learning algorithm</li>
      <li>Define $H$ as the set of all hypothesis used in certain class of algorithm</li>
      <li>The process of empirical risk minimization is then a way of picking the best hypothesis $h$ in the set $H$
<script type="math/tex">\hat{h} = arg\; \min_{h\in H}\hat{\xi}(h)</script></li>
    </ul>
  </li>
</ul>

<p><strong>Example</strong>
<strong>Conclusions</strong></p>

  </div>
  
  <!-- Related posts -->
  

  <!-- Disqus --><a class="u-url" href="/2017/08/02/learning_theory.html" hidden></a>
</article>


<script id="dsq-count-scr" src="//everitt257.disqus.com/count.js" async></script>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Everitt&#39;s blog</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Everitt&#39;s blog</li><li><a class="u-email" href="mailto:everitt257@gmail.com">everitt257@gmail.com</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/everitt257"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">everitt257</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>This site fancies machine learning and problems in engineerning in general.</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
